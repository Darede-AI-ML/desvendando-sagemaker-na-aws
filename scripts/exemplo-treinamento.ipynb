{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos de Machine Learning - Treinamento AWS SageMaker\n",
    "\n",
    "Este notebook contém exemplos práticos para o treinamento de Machine Learning com AWS SageMaker.\n",
    "\n",
    "**Conteúdo:**\n",
    "1. Análise Exploratória de Dados (EDA) Univariada\n",
    "2. Modelo XGBoost para Regressão\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análise Exploratória de Dados (EDA) Univariada\n",
    "\n",
    "A análise univariada examina cada variável individualmente para entender suas características:\n",
    "- Estatísticas descritivas (média, mediana, desvio padrão)\n",
    "- Assimetria (skewness)\n",
    "- Curtose (kurtosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Criar DataFrame de Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame de exemplo\n",
    "dados = pd.DataFrame({\n",
    "    'Idade': [25, 30, 22, 35, 28, 40, 27, 23, 32, 29],\n",
    "    'Rendimento': [1800, 2400, 1500, 3100, 2000, 4000, 1900, 1700, 2800, 2200]\n",
    "})\n",
    "\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Estatísticas Descritivas Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas básicas\n",
    "print(\"Estatísticas descritivas básicas:\")\n",
    "dados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Coeficiente de Assimetria (Skewness)\n",
    "\n",
    "O coeficiente de assimetria mede a simetria da distribuição:\n",
    "- **= 0**: Distribuição simétrica\n",
    "- **> 0**: Assimetria positiva (cauda à direita)\n",
    "- **< 0**: Assimetria negativa (cauda à esquerda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular coeficiente de assimetria\n",
    "print(\"Coeficiente de assimetria (skewness):\")\n",
    "print(f\"Idade: {skew(dados['Idade']):.2f}\")\n",
    "print(f\"Rendimento: {skew(dados['Rendimento']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Coeficiente de Curtose (Kurtosis)\n",
    "\n",
    "A curtose mede o \"achatamento\" da distribuição:\n",
    "- **= 3**: Distribuição normal (mesocúrtica)\n",
    "- **> 3**: Caudas pesadas (leptocúrtica)\n",
    "- **< 3**: Caudas leves (platicúrtica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de achatamento (kurtosis)\n",
    "print(\"Coeficiente de achatamento (kurtosis):\")\n",
    "print(f\"Idade: {kurtosis(dados['Idade'], fisher=False):.2f}\")\n",
    "print(f\"Rendimento: {kurtosis(dados['Rendimento'], fisher=False):.2f}\")\n",
    "\n",
    "print(\"\\nExcesso de kurtosis (kurtosis-3):\")\n",
    "print(f\"Idade: {kurtosis(dados['Idade'], fisher=True):.2f}\")\n",
    "print(f\"Rendimento: {kurtosis(dados['Rendimento'], fisher=True):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Modelo XGBoost para Regressão\n",
    "\n",
    "Nesta seção, vamos treinar um modelo XGBoost para prever valores de imóveis usando o dataset California Housing.\n",
    "\n",
    "**XGBoost (eXtreme Gradient Boosting)** é um algoritmo de ensemble baseado em árvores de decisão, muito utilizado em competições de ML devido à sua eficiência e performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Carregar o Dataset\n",
    "\n",
    "O dataset **California Housing** contém informações sobre distritos da Califórnia:\n",
    "- MedInc: Renda média\n",
    "- HouseAge: Idade média das casas\n",
    "- AveRooms: Média de quartos\n",
    "- AveBedrms: Média de quartos de dormir\n",
    "- Population: População\n",
    "- AveOccup: Média de ocupantes\n",
    "- Latitude/Longitude: Localização\n",
    "\n",
    "**Target:** MedHouseVal (valor médio das casas em $100.000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados de habitação da Califórnia\n",
    "california = fetch_california_housing()\n",
    "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "y = pd.Series(california.target, name='MedHouseVal')\n",
    "\n",
    "print(f\"Shape do dataset: {X.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar primeiras linhas\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Divisão Treino/Teste\n",
    "\n",
    "Dividimos os dados em:\n",
    "- **80%** para treino\n",
    "- **20%** para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dados de treino: {X_train.shape[0]} registros\")\n",
    "print(f\"Dados de teste: {X_test.shape[0]} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Configurar e Treinar o Modelo XGBoost\n",
    "\n",
    "**Hiperparâmetros principais:**\n",
    "- `n_estimators`: Número de árvores\n",
    "- `max_depth`: Profundidade máxima das árvores\n",
    "- `learning_rate`: Taxa de aprendizado\n",
    "- `subsample`: Fração de amostras por árvore\n",
    "- `colsample_bytree`: Fração de features por árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo XGBoost para regressão\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treino\n",
    "print(\"Treinando modelo XGBoost...\")\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "print(\"Treino concluído!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Realizar Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# Comparar valores reais vs previstos\n",
    "comparacao = pd.DataFrame({\n",
    "    'Real': y_test.values[:10],\n",
    "    'Previsto': y_pred[:10],\n",
    "    'Diferença': abs(y_test.values[:10] - y_pred[:10])\n",
    "})\n",
    "comparacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Avaliar o Desempenho do Modelo\n",
    "\n",
    "**Métricas de avaliação:**\n",
    "- **MSE** (Mean Squared Error): Erro quadrático médio\n",
    "- **MAE** (Mean Absolute Error): Erro absoluto médio\n",
    "- **MAPE** (Mean Absolute Percentage Error): Erro percentual absoluto médio\n",
    "- **R²** (Coeficiente de Determinação): Quanto da variância é explicada pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do desempenho\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"Avaliação do Modelo XGBoost (Regressão)\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"MSE : {mse:.3f}\")\n",
    "print(f\"MAE : {mae:.3f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"R²  : {r2:.3f}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Importância das Variáveis\n",
    "\n",
    "O XGBoost calcula automaticamente a importância de cada feature para as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela de importância das variáveis\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": xgb_reg.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Importância das Variáveis:\")\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico das features mais importantes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(\n",
    "    feature_importance[\"Feature\"],\n",
    "    feature_importance[\"Importance\"],\n",
    "    color='steelblue'\n",
    ")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Importância\")\n",
    "plt.ylabel(\"Variável\")\n",
    "plt.title(\"Importância das Variáveis - XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Neste notebook, exploramos:\n",
    "\n",
    "1. **EDA Univariada**: Análise de estatísticas descritivas, assimetria e curtose\n",
    "2. **XGBoost para Regressão**: Treinamento e avaliação de um modelo de ML\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "- Aplicar esses conceitos ao dataset `no-shows.csv`\n",
    "- Explorar treinamento gerenciado com SageMaker\n",
    "- Utilizar algoritmos built-in do SageMaker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
